{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e12653fc",
   "metadata": {},
   "source": [
    "## Explorinig the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f75f35b",
   "metadata": {},
   "source": [
    "**We will download the images and then trainthe model by using CNNs and ResNets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed5ae637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import torch \n",
    "import tarfile\n",
    "import torchvision\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b923b8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: .\\wt103_ids.tgz\n"
     ]
    }
   ],
   "source": [
    "# Download\n",
    "data_url = \"http://files.fast.ai/data/wt103_ids.tgz\"\n",
    "download_url(data_url,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12b6bbc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# explore from archive\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tarfile\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./wt103_ids.tgz\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr:gz\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m tar:\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mtar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextractall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\tarfile.py:2045\u001b[0m, in \u001b[0;36mTarFile.extractall\u001b[1;34m(self, path, members, numeric_owner)\u001b[0m\n\u001b[0;32m   2043\u001b[0m         tarinfo\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0o700\u001b[39m\n\u001b[0;32m   2044\u001b[0m     \u001b[38;5;66;03m# Do not set_attrs directories, as we will do that further down\u001b[39;00m\n\u001b[1;32m-> 2045\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2046\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mnumeric_owner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_owner\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2048\u001b[0m \u001b[38;5;66;03m# Reverse sort directories.\u001b[39;00m\n\u001b[0;32m   2049\u001b[0m directories\u001b[38;5;241m.\u001b[39msort(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m a: a\u001b[38;5;241m.\u001b[39mname)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\tarfile.py:2086\u001b[0m, in \u001b[0;36mTarFile.extract\u001b[1;34m(self, member, path, set_attrs, numeric_owner)\u001b[0m\n\u001b[0;32m   2083\u001b[0m     tarinfo\u001b[38;5;241m.\u001b[39m_link_target \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, tarinfo\u001b[38;5;241m.\u001b[39mlinkname)\n\u001b[0;32m   2085\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2086\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_member\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2087\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mset_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mset_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2088\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mnumeric_owner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_owner\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2089\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   2090\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrorlevel \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\tarfile.py:2159\u001b[0m, in \u001b[0;36mTarFile._extract_member\u001b[1;34m(self, tarinfo, targetpath, set_attrs, numeric_owner)\u001b[0m\n\u001b[0;32m   2156\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbg(\u001b[38;5;241m1\u001b[39m, tarinfo\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   2158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tarinfo\u001b[38;5;241m.\u001b[39misreg():\n\u001b[1;32m-> 2159\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakefile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargetpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2160\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m tarinfo\u001b[38;5;241m.\u001b[39misdir():\n\u001b[0;32m   2161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmakedir(tarinfo, targetpath)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\tarfile.py:2208\u001b[0m, in \u001b[0;36mTarFile.makefile\u001b[1;34m(self, tarinfo, targetpath)\u001b[0m\n\u001b[0;32m   2206\u001b[0m     target\u001b[38;5;241m.\u001b[39mtruncate()\n\u001b[0;32m   2207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2208\u001b[0m     \u001b[43mcopyfileobj\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mReadError\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\tarfile.py:250\u001b[0m, in \u001b[0;36mcopyfileobj\u001b[1;34m(src, dst, length, exception, bufsize)\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buf) \u001b[38;5;241m<\u001b[39m bufsize:\n\u001b[0;32m    249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munexpected end of data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 250\u001b[0m     \u001b[43mdst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remainder \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    253\u001b[0m     buf \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mread(remainder)\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "# explore from archive\n",
    "with tarfile.open('./wt103_ids.tgz','r:gz') as tar:\n",
    "    tar.extractall(path='./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69dd3581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'train']\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'archive (3)\\cifar10\\cifar10'\n",
    "print(os.listdir(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d061e92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74591a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of test examples for airplane: 5000\n",
      "['0001.png', '0002.png', '0003.png', '0004.png', '0005.png']\n"
     ]
    }
   ],
   "source": [
    "airplane_files = os.listdir('archive (3)\\\\cifar10\\\\cifar10\\\\train\\\\airplane')\n",
    "print('No of test examples for airplane:', len(airplane_files))\n",
    "print(airplane_files[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a491ad2e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'archive (3)\\\\cifar10\\\\cifar10test/ship'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ship_files \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest/ship\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo of test examples for ship:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(ship_files))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(ship_files[:\u001b[38;5;241m5\u001b[39m])\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'archive (3)\\\\cifar10\\\\cifar10test/ship'"
     ]
    }
   ],
   "source": [
    "ship_files = os.listdir(data_dir+ 'test/ship')\n",
    "print('No of test examples for ship:', len(ship_files))\n",
    "print(ship_files[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a84eeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageFolder(data_dir+'/train', transform=ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae14ac8e",
   "metadata": {},
   "source": [
    "Look at the sample element from the training dataset . Each element is given as a tuple, containing image tensor and a label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f839bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32]) 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7922, 0.7922, 0.8000,  ..., 0.8118, 0.8039, 0.7961],\n",
       "         [0.8078, 0.8078, 0.8118,  ..., 0.8235, 0.8157, 0.8078],\n",
       "         [0.8235, 0.8275, 0.8314,  ..., 0.8392, 0.8314, 0.8235],\n",
       "         ...,\n",
       "         [0.8549, 0.8235, 0.7608,  ..., 0.9529, 0.9569, 0.9529],\n",
       "         [0.8588, 0.8510, 0.8471,  ..., 0.9451, 0.9451, 0.9451],\n",
       "         [0.8510, 0.8471, 0.8510,  ..., 0.9373, 0.9373, 0.9412]],\n",
       "\n",
       "        [[0.8000, 0.8000, 0.8078,  ..., 0.8157, 0.8078, 0.8000],\n",
       "         [0.8157, 0.8157, 0.8196,  ..., 0.8275, 0.8196, 0.8118],\n",
       "         [0.8314, 0.8353, 0.8392,  ..., 0.8392, 0.8353, 0.8275],\n",
       "         ...,\n",
       "         [0.8510, 0.8196, 0.7608,  ..., 0.9490, 0.9490, 0.9529],\n",
       "         [0.8549, 0.8471, 0.8471,  ..., 0.9412, 0.9412, 0.9412],\n",
       "         [0.8471, 0.8431, 0.8471,  ..., 0.9333, 0.9333, 0.9333]],\n",
       "\n",
       "        [[0.7804, 0.7804, 0.7882,  ..., 0.7843, 0.7804, 0.7765],\n",
       "         [0.7961, 0.7961, 0.8000,  ..., 0.8039, 0.7961, 0.7882],\n",
       "         [0.8118, 0.8157, 0.8235,  ..., 0.8235, 0.8157, 0.8078],\n",
       "         ...,\n",
       "         [0.8706, 0.8392, 0.7765,  ..., 0.9686, 0.9686, 0.9686],\n",
       "         [0.8745, 0.8667, 0.8627,  ..., 0.9608, 0.9608, 0.9608],\n",
       "         [0.8667, 0.8627, 0.8667,  ..., 0.9529, 0.9529, 0.9529]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, lbl = dataset[0]\n",
    "print(img.shape,lbl)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac63bbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting Graph\n",
    "import matplotlib.pyplot as plt\n",
    "def show_sample(img, lbl):\n",
    "    print('label: ', dataset.classes[lbl],\"('+str(lbl)+)')\")\n",
    "    plt.imshow(img.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c79a452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  airplane ('+str(lbl)+)')\n"
     ]
    }
   ],
   "source": [
    "show_sample(*dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20e3655b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def split_indices(n, val_pct=0.1, seed=99):\n",
    "    # Determinr size of validation\n",
    "    n_val = int(val_pct*n)\n",
    "    # set random seed\n",
    "    np.random.seed(seed)\n",
    "    idx = np.random.permutation(n)\n",
    "    # pick first n_val indices for validation set\n",
    "    return idx[n_val:], idx[:n_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9bb3103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000 10000\n",
      "Sample validation indices: [33553  9427   199 12447 39489 42724 10822 49498  4144 36958]\n"
     ]
    }
   ],
   "source": [
    "val_pct = 0.2\n",
    "rand_seed = 42\n",
    "train_indices, val_indices = split_indices(len(dataset), val_pct, rand_seed)\n",
    "print(len(train_indices),len(val_indices))\n",
    "print('Sample validation indices:', val_indices[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "917ffcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data.dataloader import DataLoader \n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b69b8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trianing sampler and data loader\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "train_dl = DataLoader(dataset, batch_size, sampler=train_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3428677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation sampler and Dataloader\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "val_dl = DataLoader(dataset, batch_size, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1cfb58f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3087617693.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [17]\u001b[1;36m\u001b[0m\n\u001b[1;33m    def show_batch\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from torchvision.utils import make_grid\n",
    "\n",
    "def show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afbd20de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89607ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = nn.Sequential(\n",
    "                nn.Conv2d(3,8, kernel_size=3, stride=1, padding=1),\n",
    "                nn.MaxPool2d(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4067553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images.shape torch.Size([100, 3, 32, 32])\n",
      "out.shape torch.Size([100, 8, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "for img, lbl in train_dl:\n",
    "    print('images.shape', img.shape)\n",
    "    out = simple_model(img)\n",
    "    print('out.shape', out.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e41ebab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "        nn.Conv2d(3,16,kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2,2),# batch_size = 16 x 16 x 16\n",
    "    \n",
    "        nn.Conv2d(16,16,kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2,2),\n",
    "    \n",
    "    \n",
    "        nn.Conv2d(16,16,kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2,2),\n",
    "    \n",
    "    \n",
    "        nn.Conv2d(16,16,kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2,2),\n",
    "    \n",
    "    \n",
    "        nn.Conv2d(16,16,kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2,2),\n",
    "    \n",
    "       \n",
    "        nn.Flatten(),\n",
    "        nn.Linear(16,10))\n",
    "         \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "257f9977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 16, 3, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[3].weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717c1a66",
   "metadata": {},
   "source": [
    "## Training the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bcaa1a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model ,loss_func, xb,yb, opt=None, metric = None):\n",
    "    # Generate predictions\n",
    "    preds = model(xb)\n",
    "    loss = loss_func(preds, yb)\n",
    "    \n",
    "    if opt is not None:\n",
    "        # Compute gradients\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        #reset\n",
    "        opt.zero_grad()\n",
    "        \n",
    "    metric_result = None\n",
    "    if metric is not None:\n",
    "        # compute metric\n",
    "        metric_result = metric(preds, yb)\n",
    "        \n",
    "    return loss.item(), len(xb), metric_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3e20048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, model, loss_fn , train_dl,valid_dl,\n",
    "    opt_fn = None, lr = None, metric = None):\n",
    "    \n",
    "    # optimizer \n",
    "    if opt_fn is None:\n",
    "        opt_fn = torch.optim.SGD\n",
    "        opt = opt_fn(model.parameters(), lr = lr)\n",
    "        \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            train_loss,_,_ = loss_batch(model,loss_fn, xb,yb,opt)\n",
    "            \n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        res = evaluate(model, loss_fn, valid_dl, metric)\n",
    "        val_loss, total, val_metric = res\n",
    "        \n",
    "        # record loss\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        val_metrics.append(val_loss)\n",
    "        \n",
    "        # print progress\n",
    "        if metric is None:\n",
    "            print('Epoch [{}/{}], train_loss: {:4f}, val_loss: {:4f}'.format(epoch+1, epochs, train_loss, val_loss))\n",
    "            \n",
    "        else:\n",
    "            print('Epoch [{}/{}], train_loss: {:4f}, val_loss: {:4f}, val_{}: {:.4f}'.format(epoch+1, epochs, train_loss, val_loss,\n",
    "                                                                                            metric.__name, val_metric))\n",
    "            \n",
    "    return train_losses, val_losses, val_metrics\n",
    "            \n",
    "            \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "235d59ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, lbl):\n",
    "    _, preds = torch.max(outputs, dim =1)\n",
    "    return torch.sum(preds == lbl).items()/ len(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c13f14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bfc85f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(metruc_values):\n",
    "    plt.plot(metric_values,'-x')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('Accuracy vs No. of epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bb09846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf0909a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8b17ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
